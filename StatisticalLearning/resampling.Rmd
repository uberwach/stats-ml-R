---
title: "Resampling"
author: "Gerrit"
date: "05.03.2015"
output: html_document
---

Sample code that follows chapter 5 on Sampling.

---
The boot package gives bootstrapping functionality.
```{r}
require(ISLR)
require(boot)
```

We look at the Auto data set and plot miles per gallon against horsepower.

```{r}
plot(mpg~horsepower, data=Auto)
```

---

LOOCV
-----

Trying LOOCV (leave one out cross validation):

```{r}
glm.fit = glm(mpg~horsepower, data=Auto)
cv.glm(Auto,glm.fit)$delta # pretty slow
```

Second value is estimation reduced by bias. Since we use LOOCV it is not far off, but for k-folds with a smaller k this effect is going to play a bigger role. The implementation of LOOCV is inefficient a better way is to use the formula from 5.2. in the lecture:

```{r}
loocv = function(fit) {
  h = lm.influence(fit)$h
  mean((residuals(fit) / (1-h))^2)
}
```

And this yields the same result:

```{r}
loocv(glm.fit)
```

Now use cross-validation to obtain the error against the degree of a polynomial model:

```{r}
cv.error = rep(0,5)
degree = 1:5

for (d in degree) {
  glm.fit = glm(mpg ~ poly(horsepower, d), data = Auto)
  cv.error[d] = loocv(glm.fit)
}
plot(degree,cv.error,type="b")
```

It can be seen that $d = 2$ or $d = 5$ seems to be the optimal choice. However, the model is for $d = 5$ way more complex than it is for $d = 2$.
Let us see what happens if we use $d = 2$ and predict the miles per gallon for the horse powers from $1$ to $200$.

```{r}
glm.fit = glm(mpg ~ poly(horsepower,2), data = Auto)
horsepower = 1:200
predicted.mpg = predict(glm.fit, data.frame(horsepower = horsepower))
plot(horsepower, predicted.mpg, type = "l")
```


---

ten-fold CV
-----------

Try out $10$-fold CV (partition data set into $10$ chunks and use each chunk as a test set while training with the others).

```{r}
cv.error10 = rep(0,5)
for (d in degree) {
  glm.fit = glm(mpg ~ poly(horsepower,d), data = Auto)
  cv.error10[d] = cv.glm(Auto, glm.fit, K = 10)$delta[1]
}
plot(degree, cv.error10, type = "b")
lines(degree, cv.error10, type = "b", col = "red")
```

---

Bootstrap
--------

```{r}
alpha = function(x,y) {
  vx = var(x)
  vy = var(y)
  cxy = cov(x,y)
  (vy - cxy) / (vx + vy - 2*cxy)
}
```

```{r}
alpha(Portfolio$X, Portfolio$Y)
```

```{r}
alpha.fn = function(data, index) {
  with(data[index,], alpha(X,Y))
}
```

Test the helper function:

```{r}
alpha.fn(Portfolio,1:100)
```

```{r}
set.seed(1)
alpha.fn(Portfolio, sample(1:100, 100, replace=TRUE))
```

```{r}
boot.out = boot(Portfolio, alpha.fn, R = 1000)
boot.out
plot(boot.out)
```


---

Exercises
--------

The data set to be considered is to be considered as a time series with the values $(y,X_1,X_2)$.

Consider the linear model of $y$ on $X_1$ and $X_2$. To within 10% what is the standard error of $\beta_1$?

```{r}
load("5.R.RData")
summary(Xy)
glm.fit = glm(y ~ X1+X2, data = Xy)
```

The SE of $\beta_1$ can be read off the following table:
```{r}
summary(glm.fit)
```

Now a plot of the datapots is made with the $x$-axis iterating through all rows of the data set and for each dimension of the data one graph is drawn (so three graphs in total).

```{r}
matplot(Xy,type="l")
```

It can be seen that there is some kind of auto-correlation going on, i.e. points repeat every 10-20 rows, so our true sample size is lower. In effect our estimate of the SE of $\hat \beta_1$ is too low. (The reason is that the formula assumes we have $1000$ samples rather than $50$ due to the auto-correlation and thus assumes a lower variance of the result).

Now bootstrap shall be applied to compute the estimation for the standard error of our estimation for $\hat \beta_1$. First the test statistics:

```{r}
beta1.fn = function(data, index) {
  sampledata = data[index,]
  lm.fit = lm(y~., data = sampledata)
  summary(lm.fit)$coefficients[2,1] # selects beta 1
}
```

```{r}
boot(data = Xy, statistic = beta1.fn, R = 1000)
```

And timeseries bootstrap. l is the block length while sim = 'fixed' means that contiguous blocks are chosen, n.sim is how many samples are picked with replacements for each bootstrap sample step.). So in conclusion it runs $R = 1000$ bootstrap steps and in each samples $n.sim/l = 10$ contiguous blocks of length $100$ in the time series.

```{r}
tsboot(tseries = Xy, statistic = beta1.fn, R = 1000, n.sim = 1000, l = 100, sim = 'fixed')
```

The block bootstrap does a better job of mimicking the original sampling procedure, because it preserves the autocorrelation. The normal bootstrap assumes that sampling has been done i.i.d.