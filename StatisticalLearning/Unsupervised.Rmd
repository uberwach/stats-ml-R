---
title: "Unsupervised"
author: "Gerrit"
date: "01.04.2015"
output: html_document
---

Principal Components
====================

```{r}
dimnames(USArrests)
apply(USArrests, 2, mean)
apply(USArrests, 2, var)
```

It can be seen that `Assault` has a way larger variance than the other variables. Standardize the variables when performing PCA.

```{r}
pca.out = prcomp(USArrests, scale = TRUE)
pca.out
names(pca.out)
biplot(pca.out, scale = 0, cex = .6)
```

K-Means Clustering
==================

```{r}
set.seed(101)
x = matrix(rnorm(100*2), 100, 2)
xmean = matrix(rnorm(8, sd = 4), 4, 2)
which = sample(1:4, 100, replace = TRUE)
x = x + xmean[which,]
plot(x, col = which, pch = 19)
```

`which` contains the true cluster IDs (that made the points be sampled from a different distribution than th eothers).

```{r}
km.out  = kmeans(x, 4, nstart = 15)
km.out
plot(x, col = km.out$cluster, cex = 2, pch = 1, lwd = 2)
points(x, col = c(4,3,2,1)[which], pch = 19)
```

Hierarchical Clustering
-----------------------

```{r}
hc.complete = hclust(dist(x), method = "complete")
plot(hc.complete)
hc.single = hclust(dist(x), method = "single")
plot(hc.single)
hc.average = hclust(dist(x), method = "average")
plot(hc.average)
```


```{r}
# cutree gives a vector of assignets
# here for 4 assignments.
hc.cut = cutree(hc.complete, 4)
table(hc.cut, which) # how much information is lost?
# i.e. look at misclassifications
table(hc.cut, km.out$cluster)
```

Label the group membership to the leaves of the dendrogram.

```{r}
plot(hc.complete, labels = which)
```

Exercises
---------

1. Question can be found under "Cumulative Proportion" under PC5.

```{r}
load("10.R.RData")
x.total = rbind(x, x.test)
y.total = rbind(y, y.test)

pca.out = prcomp(x.total, scale = TRUE)
summary(pca.out)
biplot(pca.out, scale = 0, cex = .6)
```

2. Project our data frame to the first five PCA components, fit a model and do a prediction.

Build the model on the components.
```{r}
x.pca = pca.out$x[1:300, 1:5]
x.test.pca = pca.out$x[301:1300, 1:5]
lm = lm(y ~ ., data = data.frame(y, x.pca))
summary(lm)
```

```{r}
y.test.pred = predict(lm, newdata = data.frame(x.test.pca))
MSE = mean((y.test.pred - y.test)^2)
MSE
```




